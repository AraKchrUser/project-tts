{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 21 13:19:16 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.147.05   Driver Version: 525.147.05   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  Off |\n",
      "|  0%   49C    P8    19W / 450W |      0MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install display_tree\n",
    "# !pip3 install requests==2.27.0\n",
    "# !pip show requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"http_proxy\"]  = \"http://proxy.ad.speechpro.com:3128\"\n",
    "os.environ[\"https_proxy\"] = \"http://proxy.ad.speechpro.com:3128\"\n",
    "os.environ[\"ftp_proxy\"]   = \"http://proxy.ad.speechpro.com:3128\"\n",
    "\n",
    "# os.environ['CURL_CA_BUNDLE'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cutils import create_chunk_dataset, del_folder, load_checkpoint\n",
    "from calc_content import create_hubert_content\n",
    "from clustering import incremental_clustering, PseudoPhonemes\n",
    "from dataset import Text2PseudoPhonemes\n",
    "from models import TextEncoder\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import *\n",
    "import json\n",
    "\n",
    "import wget\n",
    "import torch\n",
    "from safetensors.torch import load_file\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# !pip install anyascii\n",
    "            #  gruut\n",
    "            #  bnunicodenormalizer\n",
    "            #  bnnumerizer\n",
    "            #  bangla\n",
    "            #  inflect\n",
    "            #  jamo\n",
    "            #  jieba\n",
    "            #  pypinyin\n",
    "            # mutagen\n",
    "# from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
    "# from TTS.tts.configs.vits_config import VitsConfig\n",
    "\n",
    "\n",
    "def path(_path):\n",
    "    return \"./examples/\" / Path(_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rudevices_chunk/\n",
      "├── 3/\n",
      "│   ├── 9/\n",
      "│   │   ├── 0f1576b3-073d-4d08-b6c1-98b0400cad8e.txt\n",
      "│   │   ├── 0f1576b3-073d-4d08-b6c1-98b0400cad8e.wav\n",
      "│   │   ├── 4750d7d6-cf38-440f-9449-19e5a500acf7.txt\n",
      "│   │   ├── 4750d7d6-cf38-440f-9449-19e5a500acf7.wav\n",
      "│   │   ├── 49d0f2e9-f9ae-4186-8ed9-e6330f06af58.txt\n",
      "│   │   ├── 49d0f2e9-f9ae-4186-8ed9-e6330f06af58.wav\n",
      "│   │   ├── eeb16c30-6100-430b-b871-c02c6bd740ee.txt\n",
      "│   │   └── eeb16c30-6100-430b-b871-c02c6bd740ee.wav\n",
      "│   └── d/\n",
      "│       ├── 0f9afddb-c797-44d1-b9e7-2d21bd6b9780.txt\n",
      "│       ├── 0f9afddb-c797-44d1-b9e7-2d21bd6b9780.wav\n",
      "│       ├── 7fec0bb5-2e94-43dd-bd69-6b5700a56563.txt\n",
      "│       ├── 7fec0bb5-2e94-43dd-bd69-6b5700a56563.wav\n",
      "│       ├── c51d1a43-7f92-4879-bcf0-2766bb7d2287.txt\n",
      "│       ├── c51d1a43-7f92-4879-bcf0-2766bb7d2287.wav\n",
      "│       ├── da2f8a2a-4b81-4e83-9370-89a87ec02ff7.txt\n",
      "│       └── da2f8a2a-4b81-4e83-9370-89a87ec02ff7.wav\n",
      "└── d/\n",
      "    ├── 5/\n",
      "    │   ├── 2966daa6-6cd8-4444-bc2b-5eacc7b3912f.txt\n",
      "    │   ├── 2966daa6-6cd8-4444-bc2b-5eacc7b3912f.wav\n",
      "    │   ├── 342b88f8-aae4-4473-b50c-74d801d5b047.txt\n",
      "    │   ├── 342b88f8-aae4-4473-b50c-74d801d5b047.wav\n",
      "    │   ├── 479d6e42-2d00-42a3-8791-3e95fd657513.txt\n",
      "    │   ├── 479d6e42-2d00-42a3-8791-3e95fd657513.wav\n",
      "    │   ├── afa877f3-901c-4118-b322-b29a70cbb5e7.txt\n",
      "    │   └── afa877f3-901c-4118-b322-b29a70cbb5e7.wav\n",
      "    └── e/\n",
      "        ├── 1683334d-4017-4e7c-8b79-17bb89465b5d.txt\n",
      "        ├── 1683334d-4017-4e7c-8b79-17bb89465b5d.wav\n",
      "        ├── 253fd4bb-5115-4d87-ba5a-c85be435c3f1.txt\n",
      "        ├── 253fd4bb-5115-4d87-ba5a-c85be435c3f1.wav\n",
      "        ├── 8596d40a-474f-45dc-b184-8a67f308d050.txt\n",
      "        ├── 8596d40a-474f-45dc-b184-8a67f308d050.wav\n",
      "        ├── be4cff9b-d71d-4464-a74c-0c6248a366c0.txt\n",
      "        └── be4cff9b-d71d-4464-a74c-0c6248a366c0.wav\n"
     ]
    }
   ],
   "source": [
    "create_chunk_dataset(\"../../NIR/RuDevices\", out_dataset=path(\"rudevices_chunk\"), display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314cda50-5039-44ce-bd93-9cc9dc66daf2.txt\n",
      "314cda50-5039-44ce-bd93-9cc9dc66daf2.wav\n",
      "809f7596-88dd-4e5a-95f4-7b8c322ee5ea.txt\n",
      "809f7596-88dd-4e5a-95f4-7b8c322ee5ea.wav\n",
      "b56f9ded-9365-416d-be97-f9c77746d163.txt\n",
      "b56f9ded-9365-416d-be97-f9c77746d163.wav\n",
      "d18f257d-ca75-4b8d-89a3-18c343b83990.txt\n",
      "d18f257d-ca75-4b8d-89a3-18c343b83990.wav\n"
     ]
    }
   ],
   "source": [
    "!ls examples/rudevices_chunk/1/1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# git clone lengyue233/content-vec-best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir ../../hfmodels\n",
    "# download_hf_model(\"lengyue233/content-vec-best\", \"../../hfmodels\") #TODO: Add final proj layer in lengyue233/content-vec-best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_jobs=1\n",
      "{'hmodel_id': '../../hfmodels/content-vec-best', 'data_sr': 16000, 'out_dir': PosixPath('examples/extracted_contents'), 'device': 'cuda', 'rel_to': PosixPath('examples/rudevices_chunk')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  2.93it/s]\n"
     ]
    }
   ],
   "source": [
    "#TODO: Add final proj layer in lengyue233/content-vec-best\n",
    "del_folder(path(\"extracted_contents\"))\n",
    "create_hubert_content(\n",
    "    data_dir=path(\"rudevices_chunk\"), out_dir=path(\"extracted_contents\"), \n",
    "    njobs=1, pretrain_path=\"../../hfmodels/content-vec-best\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hubert contents shape: (874, 768), 2.56 MB\n",
      "hubert contents shape: (670, 768), 1.96 MB\n",
      "hubert contents shape: (663, 768), 1.94 MB\n",
      "hubert contents shape: (392, 768), 1.15 MB\n",
      "Clustering time 0.36 seconds\n"
     ]
    }
   ],
   "source": [
    "incremental_clustering(\n",
    "    path(\"extracted_contents\"), path(\"clusters/clusters.pt\"),\n",
    "    n_clusters=100, batch_size=5, data_pattern=\"*.content.pt\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = PseudoPhonemes(path(\"clusters/clusters.pt\"))\n",
    "cluster.build_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 768)\n",
      "[50]\n",
      "(1, 768)\n"
     ]
    }
   ],
   "source": [
    "data = torch.load(path(\"clusters/clusters.pt\"))\n",
    "print(data['cluster_centers'].shape)\n",
    "item = (data['cluster_centers'][50] + data['cluster_centers'][25]).reshape(1, -1)\n",
    "print(cluster.predict_cluster_center(item))\n",
    "print(cluster.get_cluster_center(item).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json  convert.py  pytorch_model.bin  README.md\n"
     ]
    }
   ],
   "source": [
    "!ls ../../hfmodels/content-vec-best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conf_p = \"../../NIR/YourTTS-RU-RUSLAN-April-30-2023_03+48PM-0000000/config.json\"\n",
    "dataset = Text2PseudoPhonemes(\n",
    "    path(\"rudevices_chunk\"), path(\"extracted_contents\"), path(\"clusters/clusters.pt\"), \n",
    "    None, None, \"ckpts/yourrtts_config.json\", #pretrain path m.b. \"../../hfmodels/content-vec-best\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16:30:41] /mnt/storage/kocharyan/sambashare/ITMO_LABS/ML/venv/local/lib/python3.8/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'tokens': tensor([112, 113, 105,  99, 102, 115, 145, 110,  97, 106, 115, 105, 145, 114,\n",
       "          102, 113, 105,  97, 108, 145,  99, 111, 145,  99, 114, 102, 145, 115,\n",
       "          128, 103, 107, 105, 102]),\n",
       "  'pseudo_ph': tensor([14, 14, 91, 91, 13, 13, 13, 13, 13, 99, 99, 92, 95, 95, 51, 77, 77, 77,\n",
       "          77, 57, 57, 57, 57, 57, 50, 50, 50, 27, 14, 33, 33, 33, 63, 63, 10, 93,\n",
       "          93, 93, 13, 13, 13, 13, 99, 81, 81, 69, 31, 63, 65, 51, 51, 51, 51, 51,\n",
       "          99, 87, 92, 44, 44, 56, 56, 13, 13, 78, 91, 91, 91, 77, 77, 77, 35, 35,\n",
       "          35, 35, 35, 49, 78, 78, 58, 53,  0, 55, 49,  1, 90, 92, 44, 44, 56, 56,\n",
       "          51, 99, 99, 69, 92, 44, 96,  9,  9, 35, 35, 35, 35, 57, 57, 90, 38, 19,\n",
       "          32, 32, 32, 31, 92, 44, 96, 51, 51, 51, 51, 25, 25, 14,  8, 48, 14, 48,\n",
       "          16, 14, 62, 62, 14, 84, 84, 84, 14, 84, 11, 11, 14, 14]),\n",
       "  'text': 'привет найти сериал во все тяжкие'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(DataLoader(dataset, batch_size=1, collate_fn=lambda batch: batch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 140 33\n"
     ]
    }
   ],
   "source": [
    "_ = next(iter(DataLoader(dataset, batch_size=1, collate_fn=lambda batch: batch)))[0]\n",
    "print(len(_['tokens']), len(_['pseudo_ph']), len(_['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir ckpts\n",
    "!cp ../../NIR/YourTTS-RU-RUSLAN-April-30-2023_03+48PM-0000000/best_model_158996.pth ckpts/yourtts_ruslan.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'characters_class': 'TTS.tts.models.vits.VitsCharacters',\n",
       " 'vocab_dict': None,\n",
       " 'pad': '_',\n",
       " 'eos': '&',\n",
       " 'bos': '*',\n",
       " 'blank': None,\n",
       " 'characters': \"ЁАБВГДЕЖЗИЙКЛМНОПСТУФХЦЧШЩЪЫЬЭЮЯабвгдежзийклмнопстуфхцчшщъыьэюяё¯·ßàáâãäæçèéêëìíîïñòóôõöùúûüÿāąćēęěīıłńōőœśūűźżǎǐǒǔабвгдежзийклмнопрстуфхцчшщъыьэюяёєіїґ–!'(),-.:;? \",\n",
       " 'punctuations': \"!'(),-.:;? \",\n",
       " 'phonemes': '',\n",
       " 'is_unique': True,\n",
       " 'is_sorted': True}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or https://huggingface.co/joefox/tts_vits_ru_hf\n",
    "\n",
    "with open(\"../../NIR/YourTTS-RU-RUSLAN-April-30-2023_03+48PM-0000000/config.json\", 'r') as f:\n",
    "    data = json.load(f)\n",
    "data['characters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_path': '/mnt/storage/kocharyan/NIR',\n",
       " 'logger_uri': None,\n",
       " 'run_name': 'YourTTS-RU-RUSLAN',\n",
       " 'project_name': 'YourTTS',\n",
       " 'run_description': '\\n            - Original YourTTS trained using RUSLAN dataset\\n        ',\n",
       " 'print_step': 50,\n",
       " 'plot_step': 100,\n",
       " 'model_param_stats': False,\n",
       " 'wandb_entity': None,\n",
       " 'dashboard_logger': 'tensorboard',\n",
       " 'log_model_step': 1000,\n",
       " 'save_step': 5000,\n",
       " 'save_n_checkpoints': 2,\n",
       " 'save_checkpoints': True,\n",
       " 'save_all_best': False,\n",
       " 'save_best_after': 10000,\n",
       " 'target_loss': 'loss_1',\n",
       " 'print_eval': False,\n",
       " 'test_delay_epochs': 0,\n",
       " 'run_eval': True,\n",
       " 'run_eval_steps': None,\n",
       " 'distributed_backend': 'nccl',\n",
       " 'distributed_url': 'tcp://localhost:54321',\n",
       " 'mixed_precision': False,\n",
       " 'epochs': 1000,\n",
       " 'batch_size': 32,\n",
       " 'eval_batch_size': 32,\n",
       " 'grad_clip': [1000, 1000],\n",
       " 'scheduler_after_epoch': True,\n",
       " 'lr': 0.001,\n",
       " 'optimizer': 'AdamW',\n",
       " 'optimizer_params': {'betas': [0.8, 0.99],\n",
       "  'eps': 1e-09,\n",
       "  'weight_decay': 0.01},\n",
       " 'lr_scheduler': None,\n",
       " 'lr_scheduler_params': {},\n",
       " 'use_grad_scaler': False,\n",
       " 'cudnn_enable': True,\n",
       " 'cudnn_deterministic': False,\n",
       " 'cudnn_benchmark': False,\n",
       " 'training_seed': 54321,\n",
       " 'model': 'vits',\n",
       " 'num_loader_workers': 8,\n",
       " 'num_eval_loader_workers': 0,\n",
       " 'use_noise_augment': False,\n",
       " 'audio': {'fft_size': 1024,\n",
       "  'sample_rate': 16000,\n",
       "  'win_length': 1024,\n",
       "  'hop_length': 256,\n",
       "  'num_mels': 80,\n",
       "  'mel_fmin': 0.0,\n",
       "  'mel_fmax': None},\n",
       " 'use_phonemes': False,\n",
       " 'phonemizer': 'espeak',\n",
       " 'phoneme_language': 'ru',\n",
       " 'compute_input_seq_cache': True,\n",
       " 'text_cleaner': 'multilingual_cleaners',\n",
       " 'enable_eos_bos_chars': False,\n",
       " 'test_sentences_file': '',\n",
       " 'phoneme_cache_path': None,\n",
       " 'characters': {'characters_class': 'TTS.tts.models.vits.VitsCharacters',\n",
       "  'vocab_dict': None,\n",
       "  'pad': '_',\n",
       "  'eos': '&',\n",
       "  'bos': '*',\n",
       "  'blank': None,\n",
       "  'characters': \"ЁАБВГДЕЖЗИЙКЛМНОПСТУФХЦЧШЩЪЫЬЭЮЯабвгдежзийклмнопстуфхцчшщъыьэюяё¯·ßàáâãäæçèéêëìíîïñòóôõöùúûüÿāąćēęěīıłńōőœśūűźżǎǐǒǔабвгдежзийклмнопрстуфхцчшщъыьэюяёєіїґ–!'(),-.:;? \",\n",
       "  'punctuations': \"!'(),-.:;? \",\n",
       "  'phonemes': '',\n",
       "  'is_unique': True,\n",
       "  'is_sorted': True},\n",
       " 'add_blank': True,\n",
       " 'batch_group_size': 48,\n",
       " 'loss_masking': None,\n",
       " 'min_audio_len': 1,\n",
       " 'max_audio_len': 160000,\n",
       " 'min_text_len': 1,\n",
       " 'max_text_len': inf,\n",
       " 'compute_f0': False,\n",
       " 'compute_energy': False,\n",
       " 'compute_linear_spec': True,\n",
       " 'precompute_num_workers': 12,\n",
       " 'start_by_longest': True,\n",
       " 'shuffle': False,\n",
       " 'drop_last': False,\n",
       " 'datasets': [{'formatter': 'ruslan',\n",
       "   'dataset_name': 'ruslan',\n",
       "   'path': '/mnt/storage/kocharyan/NIR/../datasets_ruslan/ruslan_ds/',\n",
       "   'meta_file_train': 'metadata.csv',\n",
       "   'ignored_speakers': ['p261',\n",
       "    'p225',\n",
       "    'p294',\n",
       "    'p347',\n",
       "    'p238',\n",
       "    'p234',\n",
       "    'p248',\n",
       "    'p335',\n",
       "    'p245',\n",
       "    'p326',\n",
       "    'p302'],\n",
       "   'language': 'ru',\n",
       "   'phonemizer': '',\n",
       "   'meta_file_val': '',\n",
       "   'meta_file_attn_mask': ''}],\n",
       " 'test_sentences': [[\"It took me quite a long time to develop a voice, and now that I have it I'm not going to be silent.\"],\n",
       "  ['Be a voice, not an echo.'],\n",
       "  [\"I'm sorry Dave. I'm afraid I can't do that.\"],\n",
       "  [\"This cake is great. It's so delicious and moist.\"],\n",
       "  ['Prior to November 22, 1963.']],\n",
       " 'eval_split_max_size': 256,\n",
       " 'eval_split_size': 0.01,\n",
       " 'use_speaker_weighted_sampler': False,\n",
       " 'speaker_weighted_sampler_alpha': 1.0,\n",
       " 'use_language_weighted_sampler': False,\n",
       " 'language_weighted_sampler_alpha': 1.0,\n",
       " 'use_length_weighted_sampler': False,\n",
       " 'length_weighted_sampler_alpha': 1.0,\n",
       " 'model_args': {'num_chars': 177,\n",
       "  'out_channels': 513,\n",
       "  'spec_segment_size': 32,\n",
       "  'hidden_channels': 192,\n",
       "  'hidden_channels_ffn_text_encoder': 768,\n",
       "  'num_heads_text_encoder': 2,\n",
       "  'num_layers_text_encoder': 10,\n",
       "  'kernel_size_text_encoder': 3,\n",
       "  'dropout_p_text_encoder': 0.1,\n",
       "  'dropout_p_duration_predictor': 0.5,\n",
       "  'kernel_size_posterior_encoder': 5,\n",
       "  'dilation_rate_posterior_encoder': 1,\n",
       "  'num_layers_posterior_encoder': 16,\n",
       "  'kernel_size_flow': 5,\n",
       "  'dilation_rate_flow': 1,\n",
       "  'num_layers_flow': 4,\n",
       "  'resblock_type_decoder': '2',\n",
       "  'resblock_kernel_sizes_decoder': [3, 7, 11],\n",
       "  'resblock_dilation_sizes_decoder': [[1, 3, 5], [1, 3, 5], [1, 3, 5]],\n",
       "  'upsample_rates_decoder': [8, 8, 2, 2],\n",
       "  'upsample_initial_channel_decoder': 512,\n",
       "  'upsample_kernel_sizes_decoder': [16, 16, 4, 4],\n",
       "  'periods_multi_period_discriminator': [2, 3, 5, 7, 11],\n",
       "  'use_sdp': True,\n",
       "  'noise_scale': 1.0,\n",
       "  'inference_noise_scale': 0.667,\n",
       "  'length_scale': 1,\n",
       "  'noise_scale_dp': 1.0,\n",
       "  'inference_noise_scale_dp': 1.0,\n",
       "  'max_inference_len': None,\n",
       "  'init_discriminator': True,\n",
       "  'use_spectral_norm_disriminator': False,\n",
       "  'use_speaker_embedding': False,\n",
       "  'num_speakers': 0,\n",
       "  'speakers_file': '/mnt/storage/kocharyan/NIR/YourTTS-RU-RUSLAN-April-30-2023_03+48PM-0000000/speakers.pth',\n",
       "  'd_vector_file': ['/mnt/storage/kocharyan/NIR/../datasets_ruslan/ruslan_ds/speakers.pth'],\n",
       "  'speaker_embedding_channels': 256,\n",
       "  'use_d_vector_file': True,\n",
       "  'd_vector_dim': 512,\n",
       "  'detach_dp_input': True,\n",
       "  'use_language_embedding': False,\n",
       "  'embedded_language_dim': 4,\n",
       "  'num_languages': 0,\n",
       "  'language_ids_file': None,\n",
       "  'use_speaker_encoder_as_loss': False,\n",
       "  'speaker_encoder_config_path': '/home/stc/.local/share/tts/tts_models--multilingual--multi-dataset--your_tts/config_se.json',\n",
       "  'speaker_encoder_model_path': '/home/stc/.local/share/tts/tts_models--multilingual--multi-dataset--your_tts/model_se.pth',\n",
       "  'condition_dp_on_speaker': True,\n",
       "  'freeze_encoder': False,\n",
       "  'freeze_DP': False,\n",
       "  'freeze_PE': False,\n",
       "  'freeze_flow_decoder': False,\n",
       "  'freeze_waveform_decoder': False,\n",
       "  'encoder_sample_rate': None,\n",
       "  'interpolate_z': True,\n",
       "  'reinit_DP': False,\n",
       "  'reinit_text_encoder': False},\n",
       " 'lr_gen': 0.0002,\n",
       " 'lr_disc': 0.0002,\n",
       " 'lr_scheduler_gen': 'ExponentialLR',\n",
       " 'lr_scheduler_gen_params': {'gamma': 0.999875, 'last_epoch': -1},\n",
       " 'lr_scheduler_disc': 'ExponentialLR',\n",
       " 'lr_scheduler_disc_params': {'gamma': 0.999875, 'last_epoch': -1},\n",
       " 'kl_loss_alpha': 1.0,\n",
       " 'disc_loss_alpha': 1.0,\n",
       " 'gen_loss_alpha': 1.0,\n",
       " 'feat_loss_alpha': 1.0,\n",
       " 'mel_loss_alpha': 45.0,\n",
       " 'dur_loss_alpha': 1.0,\n",
       " 'speaker_encoder_loss_alpha': 9.0,\n",
       " 'return_wav': True,\n",
       " 'use_weighted_sampler': True,\n",
       " 'weighted_sampler_attrs': {'speaker_name': 1.0},\n",
       " 'weighted_sampler_multipliers': {},\n",
       " 'r': 1,\n",
       " 'num_speakers': 0,\n",
       " 'use_speaker_embedding': False,\n",
       " 'speakers_file': '/mnt/storage/kocharyan/NIR/YourTTS-RU-RUSLAN-April-30-2023_03+48PM-0000000/speakers.pth',\n",
       " 'speaker_embedding_channels': 256,\n",
       " 'language_ids_file': None,\n",
       " 'use_language_embedding': False,\n",
       " 'use_d_vector_file': True,\n",
       " 'd_vector_file': ['/mnt/storage/kocharyan/NIR/../datasets_ruslan/ruslan_ds/speakers.pth'],\n",
       " 'd_vector_dim': 512}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# symbols_dict = {\n",
    "#     \"_pad\" : '_',\n",
    "#     \"_punctuation\" : ' !+,-.:;?«»—',\n",
    "#     \"_letters\" : 'абвгдежзийклмнопрстуфхцчшщъыьэюяё',\n",
    "#     \"_letters_ipa\" : \"ɑɐɒæɓʙβɔɕçɗɖðʤəɘɚɛɜɝɞɟʄɡɠɢʛɦɧħɥʜɨɪʝɭɬɫɮʟɱɯɰŋɳɲɴøɵɸθœɶʘɹɺɾɻʀʁɽʂʃʈʧʉʊʋⱱʌɣɤʍχʎʏʑʐʒʔʡʕʢǀǁǂǃˈˌːˑʼʴʰʱʲʷˠˤ˞↓↑→↗↘'̩'ᵻ\",\n",
    "# }\n",
    "\n",
    "# len(dataset.symbols) #dataset symbols len\n",
    "\n",
    "# #OR\n",
    "\n",
    "# dataset._symbol_to_id = { \" \": 0, \"!\": 37, \"+\": 40, \",\": 39, \".\": 36, \":\": 2, \"<pad>\": 42, \"<unk>\": 41, \"?\": 38, \"_\": 1, \"а\": 3, \"б\": 4, \"в\": 5, \"г\": 6, \"д\": 7, \"е\": 8, \"ж\": 10, \"з\": 11, \"и\": 12, \"й\": 13, \"к\": 14, \"л\": 15, \"м\": 16, \"н\": 17, \"о\": 18, \"п\": 19, \"р\": 20, \"с\": 21, \"т\": 22, \"у\": 23, \"ф\": 24, \"х\": 25, \"ц\": 26, \"ч\": 27, \"ш\": 28, \"щ\": 29, \"ъ\": 30, \"ы\": 31, \"ь\": 32, \"э\": 33, \"ю\": 34, \"я\": 35, \"ё\": 9 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177, 134, 134)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.symbols), len(dataset._symbol_to_id), len({s: i for i, s in enumerate(dataset.symbols)}) #WTF!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vocab         = len(dataset.symbols) # 177\n",
    "inter_channels  = 192\n",
    "hidden_channels = 192\n",
    "filter_channels = 768\n",
    "n_heads         = 2\n",
    "n_layers        = 6 # 10 for YourTTS\n",
    "kernel_size     = 3\n",
    "p_dropout       = .1\n",
    "\n",
    "prior_encoder = TextEncoder(\n",
    "    n_vocab, inter_channels, hidden_channels, filter_channels, \n",
    "    n_heads, n_layers, kernel_size, p_dropout,\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_encoder = load_checkpoint(prior_encoder,  #trablse\n",
    "                                \"ckpts/yourtts_ruslan.pth\", \n",
    "                                \"text_encoder\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: проверить все размерности массивов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
