
Есть 4 папки:
- DiffVC: модель для преобразования голоса на основе диффузии. Принимает 2 аудиозаписи.
Одна референсная, другая таргетная. Пользуясь наработками из основного репозитория (сслыка в ReadMe соответсвующей папки)
собрал все в один класс для инференса, делал это еще в марте этого года (кажется если поискать то можно найти в других репо решения этого вопроса, но и этим можно пользоваться я думаю).
- VITS: такой же кейс, что и выше. Различия в том, что модель основана на вариационном выводе, а для преобразования требует референсного спикера из обучаемого корпуса.  
- YourTTS-train: тут брал за основу рецепт из репо coqui/tts и использовал для данных
- So-VITS: еще работаем над этим

Что нужно сделать:
- Зарефакторить код 
- Добавить проброску параметров через argparse 
- Потестить
- Собрать окружение