{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements-list\n",
    "# !pip install faster-whisper==1.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -rotobuf (/mnt/storage/kocharyan/sambashare/ITMO_LABS/ML/venv/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/mnt/storage/kocharyan/sambashare/ITMO_LABS/ML/venv/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -lotly (/mnt/storage/kocharyan/sambashare/ITMO_LABS/ML/venv/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ip (/mnt/storage/kocharyan/sambashare/ITMO_LABS/ML/venv/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution - (/mnt/storage/kocharyan/sambashare/ITMO_LABS/ML/venv/lib/python3.8/site-packages)\u001b[0m\n",
      "Name: torch\n",
      "Version: 2.0.1+cu117\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3\n",
      "Location: /mnt/storage/kocharyan/sambashare/ITMO_LABS/ML/venv/lib/python3.8/site-packages\n",
      "Requires: filelock, jinja2, networkx, sympy, triton, typing-extensions\n",
      "Required-by: accelerate, adan-pytorch, asteroid-filterbanks, julius, lightning, openai-whisper, pyannote.audio, pytorch-lightning, pytorch-metric-learning, so-vits-svc-fork, speechbrain, thop, torch-audiomentations, torch-pitch-shift, torchaudio, torchcrepe, torchmetrics, torchvision, trainer, triton, ultralytics\n"
     ]
    }
   ],
   "source": [
    "!pip show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 15 11:28:45 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.147.05   Driver Version: 525.147.05   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  Off |\n",
      "|  0%   49C    P8    19W / 450W |      0MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/storage/kocharyan/sambashare/ITMO_LABS/ML/venv/local/lib/python3.8/site-packages/tqdm_joblib/__init__.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'whisperx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m del_folder, create_chunk_dataset\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhubert_proc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_hubert, create_hubert_content\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mclustering\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cluster_training_on_data\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mso_vits\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattentions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Encoder\n",
      "File \u001b[0;32m/mnt/storage/kocharyan/speech-editing-project/hubert_proc.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_dataset\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mclustering\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CharClusters\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minferencers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m/mnt/storage/kocharyan/speech-editing-project/datasets.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwhisperx\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'whisperx'"
     ]
    }
   ],
   "source": [
    "from utils import del_folder, create_chunk_dataset\n",
    "from hubert_proc import get_hubert, create_hubert_content\n",
    "from clustering import cluster_training_on_data\n",
    "\n",
    "from so_vits.modules.attentions import Encoder\n",
    "import whisperx\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "os.environ[\"http_proxy\"] = \"http://proxy.ad.speechpro.com:3128\"\n",
    "os.environ[\"https_proxy\"] = \"http://proxy.ad.speechpro.com:3128\"\n",
    "os.environ[\"ftp_proxy\"] = \"http://proxy.ad.speechpro.com:3128\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path(_path):\n",
    "    return \"./examples/\" / Path(_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  1  2  3  4  5  6  7\t8  9  a  b  c  d  e  f\n"
     ]
    }
   ],
   "source": [
    "!ls ../NIR/RuDevices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rudevices_chunk/\n",
      "├── 9/\n",
      "│   ├── d/\n",
      "│   │   ├── 22bc8786-a705-4c5e-a7c2-1062fd43961e.wav\n",
      "│   │   ├── 682be63f-cce9-436d-9694-754d70e68499.wav\n",
      "│   │   ├── 6f47e71e-55d8-4aa8-a059-eed74a5e6744.wav\n",
      "│   │   └── bc9c83f8-964a-4a20-a930-3e3c98aeead8.wav\n",
      "│   └── e/\n",
      "│       ├── 685d1b73-8af8-4b19-b207-a52fe831b4a0.wav\n",
      "│       ├── 8b0f97c8-55c8-4c97-9f68-9a091c1d8159.wav\n",
      "│       ├── 906696b8-8c92-4225-8808-b08c9029c11a.wav\n",
      "│       └── baa26e05-8782-4df8-8ade-262e50b3a34f.wav\n",
      "└── d/\n",
      "    ├── 3/\n",
      "    │   ├── 671b7945-fd12-46d4-ae65-bbf2ad8caf90.wav\n",
      "    │   ├── 946c0fe8-eb20-47e6-85d2-9ed8a5ed1795.wav\n",
      "    │   ├── ab0f7026-2d61-4c71-a5ca-1f361457c740.wav\n",
      "    │   └── eede5ec1-2865-4981-b20b-1b5b86a6bc83.wav\n",
      "    └── 9/\n",
      "        ├── 5b4aec41-5046-416b-8c32-4303fcceb49d.wav\n",
      "        ├── 6bd71d75-bd7c-483f-b841-7ed934954088.wav\n",
      "        ├── 84bb18fa-59e3-460c-946d-4af2426b44aa.wav\n",
      "        └── c8b54f05-2a9e-40c1-87fd-7d67b6bd82f0.wav\n"
     ]
    }
   ],
   "source": [
    "create_chunk_dataset(\"../NIR/RuDevices\", out_dataset=path(\"rudevices_chunk\"), display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2.87G/2.87G [02:37<00:00, 19.6MiB/s]\n",
      "100%|█████████████████████████████████████| 2.87G/2.87G [02:43<00:00, 18.9MiB/s]\n",
      "100%|█████████████████████████████████████| 2.87G/2.87G [02:57<00:00, 17.4MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no default alignment model set for this language (ru).                Please find a wav2vec2.0 model finetuned on this language in https://huggingface.co/models, then pass the model name in --align_model [MODEL_NAME]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No default align-model for language: ru",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/mnt/storage/kocharyan/sambashare/ITMO_LABS/ML/venv/local/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n    r = call_item()\n  File \"/mnt/storage/kocharyan/sambashare/ITMO_LABS/ML/venv/local/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/mnt/storage/kocharyan/sambashare/ITMO_LABS/ML/venv/local/lib/python3.8/site-packages/joblib/parallel.py\", line 589, in __call__\n    return [func(*args, **kwargs)\n  File \"/mnt/storage/kocharyan/sambashare/ITMO_LABS/ML/venv/local/lib/python3.8/site-packages/joblib/parallel.py\", line 589, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/mnt/storage/kocharyan/speech-editing-project/whisper_proc.py\", line 23, in _batch_whisper_infer\n    whisper = WhisperXInference(\"float16\", device, \"ru\")\n  File \"/mnt/storage/kocharyan/speech-editing-project/inferencers.py\", line 26, in __init__\n    align_model, metadata = whisperx.load_align_model(language_code=self.language, device=self.device)\n  File \"/mnt/storage/kocharyan/speech-editing-project/whisperx/transcribe.py\", line 596, in load_align_model\n    raise ValueError(f\"No default align-model for language: {language_code}\")\nValueError: No default align-model for language: ru\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# del_folder(Path(\"ali\"))\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcreate_hubert_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrudevices_chunk\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mali\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# TODO: проблемы с whisperX\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/storage/kocharyan/speech-editing-project/hubert_proc.py:116\u001b[0m, in \u001b[0;36mcreate_hubert_content\u001b[0;34m(data_dir, sr, out_dir, device)\u001b[0m\n\u001b[1;32m    110\u001b[0m file_chunks \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray_split(audio_files, n_jobs)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# files_to_whispout = Parallel(n_jobs=-1)(delayed(_whisper_inf)( # make batch inf ?!\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m#     data[0], dataset.dataset[i]\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# ) for i, data in enumerate(loader))\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# files_to_whispout = [_whisper_inf(data[0], dataset.dataset[i]) for i, data in enumerate(loader)]\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m files_to_whispout \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_batch_whisper_infer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_chunks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# files_to_whispout = [_batch_whisper_infer(chunk, pbar) for (pbar, chunk) in enumerate(file_chunks)]\u001b[39;00m\n\u001b[1;32m    121\u001b[0m files_to_whispout \u001b[38;5;241m=\u001b[39m flatten(files_to_whispout)\n",
      "File \u001b[0;32m/mnt/storage/kocharyan/sambashare/ITMO_LABS/ML/venv/local/lib/python3.8/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/storage/kocharyan/sambashare/ITMO_LABS/ML/venv/local/lib/python3.8/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/storage/kocharyan/sambashare/ITMO_LABS/ML/venv/local/lib/python3.8/site-packages/joblib/parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1692\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1693\u001b[0m \n\u001b[1;32m   1694\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1695\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1696\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1697\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[0;32m-> 1699\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1700\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1702\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/storage/kocharyan/sambashare/ITMO_LABS/ML/venv/local/lib/python3.8/site-packages/joblib/parallel.py:1734\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[1;32m   1731\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1732\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1734\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/storage/kocharyan/sambashare/ITMO_LABS/ML/venv/local/lib/python3.8/site-packages/joblib/parallel.py:736\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    730\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[0;32m--> 736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/mnt/storage/kocharyan/sambashare/ITMO_LABS/ML/venv/local/lib/python3.8/site-packages/joblib/parallel.py:754\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 754\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: No default align-model for language: ru"
     ]
    }
   ],
   "source": [
    "# del_folder(Path(\"ali\"))\n",
    "create_hubert_content(data_dir=path(\"rudevices_chunk\"), out_dir=path(\"ali\")) # TODO: проблемы с whisperX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_training_on_data(path(\"ali\"), path(\"clusters/clusters.pt\"), 2, 2048, \"*.content.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "char_clusters = CharClusters(\"clusters/clusters.pt\")\n",
    "char_clusters.build_chars_clusters()\n",
    "\n",
    "data = torch.load(\"clusters/clusters.pt\")\n",
    "_data = (data[\"а\"]['cluster_centers'][0] + data[\"ф\"]['cluster_centers'][0]).reshape(1, -1)\n",
    "print(_data.shape)\n",
    "c = char_clusters.get_cluster_center(\"а\", _data)\n",
    "print(c.shape)\n",
    "_data, c\n",
    "\n",
    "\n",
    "path = \"ali/ё/rudevices_chunk.6.b.1baf3c9f-6672-4c32-abe6-e82f7ee9d40a.wav.content.pt\"\n",
    "torch.load(path)[\"content\"].shape\n",
    "\n",
    "\n",
    "file = 'rudevices_chunk/6/b/887fc29a-fdf8-4199-bfcd-2134c7fe1db8.wav'\n",
    "f = torch.load(\"ali/align.pt\")['ali'][file]\n",
    "f\n",
    "\n",
    "\n",
    "pprint([p for p in Path(\"rudevices_chunk/\").rglob(\"*.wav\")]) \n",
    "\n",
    "get_label_for_file('rudevices_chunk/1/4/9ef07055-3976-4d5c-96d3-6e41a52fc190.wav')\n",
    "\n",
    "\n",
    "!cat rudevices_chunk/1/4/9ef07055-3976-4d5c-96d3-6e41a52fc190.txt\n",
    "\n",
    "\n",
    "print(clac_label_res[0], clac_label_res[1], clac_label_res[1].count(')'), clac_label_res[2], sep='\\n\\n')\n",
    "\n",
    "\n",
    "predict = hubert_inference('rudevices_chunk/6/b/887fc29a-fdf8-4199-bfcd-2134c7fe1db8.wav', hubert_inf, processor, \"cuda\")\n",
    "predict.shape\n",
    "\n",
    "display_tree(\"rudevices_chunk/\")\n",
    "\n",
    "!ls rudevices_chunk/1/4\n",
    "processor, hubert_model, hubert_inf = get_hubert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    p.with_suffix(\".txt\").as_posix()[len(\"rudevices_chunk/\"):] \n",
    "    for p in Path(\"rudevices_chunk/\").rglob(\"*.wav\")\n",
    "]\n",
    "# print(files)\n",
    "for f in files:\n",
    "    shutil.copy(Path(\"RuDevices\") / f, Path(\"rudevices_chunk\") / f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: create config\n",
    "\n",
    "n_vocab         = 177 #52 # len(symbols) from text.symbols import symbols\n",
    "inter_channels  = 192\n",
    "hidden_channels = 192\n",
    "filter_channels = 768\n",
    "n_heads         = 2\n",
    "n_layers        = 10 #6\n",
    "kernel_size     = 3\n",
    "p_dropout       = .1\n",
    "\n",
    "prior_encoder = TextEncoder(\n",
    "    n_vocab, inter_channels, hidden_channels, filter_channels, \n",
    "    n_heads, n_layers, kernel_size, p_dropout,\n",
    ")\n",
    "\n",
    "# prior_encoder()\n",
    "# \"vist_ckpt/G_0.pth\"\n",
    "# \"enc_p\"\n",
    "prior_encoder = load_checkpoint(prior_encoder, \n",
    "                                \"YourTTS-RU-RUSLAN-April-30-2023_03+48PM-0000000/best_model_158996.pth\", \n",
    "                                \"text_encoder\", False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TextFromAudioDataset(\n",
    "    \"rudevices_chunk/\", \n",
    "    \"YourTTS-RU-RUSLAN-April-30-2023_03+48PM-0000000/config.json\",\n",
    "    processor, hubert_inf\n",
    ")\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=1)\n",
    "next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Почему len(symbols)==52 в исходной версии (по размеру эмбеддинга)\n",
    "# return phonem\n",
    "dataset = TextFromAudioDataset(\"rudevices_chunk/\", \"YourTTS-RU-RUSLAN-April-30-2023_03+48PM-0000000/config.json\")\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=1)\n",
    "text = next(iter(loader))\n",
    "\n",
    "print(open(next(iter(loader.dataset.dataset)), \"r\").read().strip())\n",
    "\n",
    "text_lengths = torch.LongTensor(1)\n",
    "text_lengths[0] = len(text[0])\n",
    "batch = text, text_lengths\n",
    "\n",
    "print(batch)\n",
    "\n",
    "prior_encoder(batch[0], batch[1])[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = TextDecoder()\n",
    "_, *forward_params, _ = prior_encoder(batch[0], batch[1])\n",
    "decoder(*forward_params, torch.ones((1, 10000)).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/RVC-Boss/GPT-SoVITS/blob/f36ca4a451e6614073d548321ad066dce73ec44d/GPT_SoVITS/configs/s2.json\n",
    "hps = {\"filter_length\": 2048, \"segment_size\": 20480, \"hop_length\": 640, \"n_speakers\": 300, \n",
    "       \"model\": {\n",
    "    \"inter_channels\": 192,\n",
    "    \"hidden_channels\": 192,\n",
    "    \"filter_channels\": 768,\n",
    "    \"n_heads\": 2,\n",
    "    \"n_layers\": 6,\n",
    "    \"kernel_size\": 3,\n",
    "    \"p_dropout\": 0.1,\n",
    "    \"resblock\": \"1\",\n",
    "    \"resblock_kernel_sizes\": [3,7,11],\n",
    "    \"resblock_dilation_sizes\": [[1,3,5],[1,3,5],[1,3,5]],\n",
    "    \"upsample_rates\": [10,8,2,2,2],\n",
    "    \"upsample_initial_channel\": 512,\n",
    "    \"upsample_kernel_sizes\": [16,16,8,2,2],\n",
    "    \"n_layers_q\": 3,\n",
    "    \"use_spectral_norm\": False,\n",
    "    \"gin_channels\": 512,\n",
    "    \"semantic_frame_rate\": \"25hz\",\n",
    "    \"freeze_quantizer\": True\n",
    "  }}\n",
    "vq_model = SynthesizerTrn(\n",
    "        hps['filter_length'] // 2 + 1,\n",
    "        hps['segment_size'] // hps['hop_length'],\n",
    "        n_speakers=hps['n_speakers'],\n",
    "        **hps['model']\n",
    "    )\n",
    "# torch.load('ali/ф/rudevices_chunk.1.d.588fa2d0-7543-49d1-b8d3-99091c2edcf5.wav.content.pt')['content'].shape\n",
    "hvec = torch.rand(*[1, 768, 215]) #.transpose(1,2).cpu()#torch.Size([1, 768, 215])\n",
    "codes = vq_model.extract_latent(hvec)\n",
    "codes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes[..., :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
